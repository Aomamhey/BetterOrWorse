import os
import pymysql
import datetime
import requests
from pyExploitDb import PyExploitDb 
from bs4 import BeautifulSoup
from collections import Counter

hostname = 'localhost'
username = 'root'
pwd = 'admin'
dbname = 'firefox'
conn = pymysql.connect(host = hostname, user = username, passwd = pwd, db = dbname)

headers = {
	        "User-Agent":"Mozilla/5.0 (Windows; U; Windows NT 5.1; zh-CN; rv:1.9.2.13) Gecko/20101203 Firefox/3.6.13",
	        #"User-Agent" = "Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.2.13) Gecko/20101206 Ubuntu/10.10 (maverick) Firefox/3.6.13",
	        "Accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
	        "Accept-Language":"zh-cn,zh;q=0.5",
	        #"Accept-Encoding":"gzip,deflate",
	        "Accept-Charset":"GB2312,utf-8;q=0.7,*;q=0.7",
	        "Keep-Alive":"115",
	        "Connection":"keep-alive"
	        }

def updateExploit(myid):
	sql = 'update cveref set isExploit=1 where id=%d'%(myid)
	try:
		cur = conn.cursor()
		cur.execute(sql)
		cur.close()
		conn.commit()
	except:
		print(sql)
		conn.rollback() 

def main():
	sql = 'select * from cveref'
	try:
		cur = conn.cursor()
		cur.execute(sql)
		result = cur.fetchall()
		cur.close()
		conn.commit()
	except:
		print(sql)
		conn.rollback()

	siteList = dict()
	exploitList = dict()
	for r in result:
		myid, cve, ref, name, refsource, tags, publication, isExploit = r
		#print(cve, ref, name, refsource, tags)
		site = ref.replace('http://', '').replace('https://', '').replace('ftp://', '').split('/')[0]
		if site not in siteList:
			siteList[site] = 1
		else:
			siteList[site] += 1
		if 'www.exploit-db.com' in ref or refsource == 'EXPLOIT-DB' or 'Exploit' in tags:
			if cve not in exploitList:
				exploitList[cve] = [ref]
			else:
				exploitList[cve].append(ref)
			updateExploit(myid)

	out = open('Firefox_ref_sites.txt', 'w')
	siteList = sorted(siteList.items(), key=lambda d : d[1], reverse = True)
	for r in siteList:
		out.write('%s %d\n'%(r[0], r[1]))

def check():
	file = open('Firefox_ref_sites.txt', 'r')
	count = 0
	for line in file:
		line = line.strip().split(' ')
		num = int(line[1])
		count += num
	print(count)

def mostSites():
	file = open('Firefox_ref_sites.txt', 'r')
	siteList = dict()
	for line in file:
		line = line.strip().split(' ')
		site = line[0]
		num = int(line[1])
		siteList[site] = num

	file.close()
	file = open('OpenBSD_ref_sites.txt', 'r')
	for line in file:
		line = line.strip().split(' ')
		site = line[0]
		num = int(line[1])
		if site not in siteList:
			siteList[site] = num
		else:
			siteList[site] += num

	siteList = sorted(siteList.items(), key=lambda d : d[1], reverse = True)
	file.close()
	file = open('mostSites.txt', 'w')
	for r in siteList:
		file.write('%s %d\n'%(r[0], r[1]))
	file.close()

#20200514
def getExploitPattern():
	sql = 'select ref from cveref where isExploit=1'
	try:
		cur = conn.cursor()
		cur.execute(sql)
		result = cur.fetchall()
		cur.close()
		conn.commit()
	except:
		print(sql)
		conn.rollback()

	siteList = dict()
	for r in result:
		ref = r[0]
		site = ref.replace('http://', '').replace('https://', '').replace('ftp://', '').split('/')[0]
		#print(site)
		if site not in siteList:
			siteList[site] = 1
		else:
			siteList[site] += 1
	out = open('OpenBSD_exploit_sites.txt', 'a')
	siteList = sorted(siteList.items(), key=lambda d : d[1], reverse = True)
	for r in siteList:
		out.write('%s %d\n'%(r[0], r[1]))

def update(cve, edbId, publication):
	sql = f"select id from cveref where cve='{cve}' and refsource='EXPLOIT-DB' and name='{edbId}'"
	try:
		cur = conn.cursor()
		cur.execute(sql)
		result = cur.fetchone()
		cur.close()
		conn.commit()
	except:
		print(sql)
		conn.rollback()
	
	if result == None:
		sql = f"insert into cveref(cve, ref, name, refsource, tags, publication, isExploit) \
						 values('{cve}', '', '{edbId}', 'EXPLOIT-DB', 'increase', '{publication}', 1)"
		try:
			cur = conn.cursor()
			cur.execute(sql)
			cur.close()
			conn.commit()
		except:
			print(sql)
			conn.rollback()
	else:
		eid = result[0]
		sql = f"update cveref set publication='{publication}' where id={eid}"
		try:
			cur = conn.cursor()
			cur.execute(sql)
			cur.close()
			conn.commit()
		except:
			print(sql)
			conn.rollback()


def getExploitFromEDB():
	cveList = []
	with open('FirefoxCveList.txt', 'r') as file:
		for line in file:
			cve = line.strip()
			cveList.append(cve)
			'''
	with open('FirefoxCveList.txt', 'r') as file:
		for line in file:
			cve = line.strip()
			cveList.append(cve)
			'''

	pedb = PyExploitDb()
	pedb.debug = False
	pedb.openFile()

	outFile = open('FirefoxExploitFromEDB.txt', 'w')
	for cve in cveList:
		results = pedb.searchCve(cve)
		if results == []:
			continue
		#返回结果中只包含一个edbID，但实际可能有多个，结果待改正
		edbId = results['edbid']
		publication = results['date']
		#print(cve, edbId, publication)
		outFile.write(f'{cve} {edbId} {publication}\n')

		update(cve, edbId, publication)


def getBid():
	file = open('tmp.txt', 'r')
	bids = []
	for line in file:
		line = line.strip().split(' ')
		for bid in line:
			if bid == '':
				continue
			if bid not in bids:
				bids.append(bid)
	file = open('OpenBSDBIDList.txt', 'w')
	for bid in bids:
		file.write(f'{bid}\n')

def updateBIDExploitTime(bid, date, url, des):
	sql = f"select id, isExploit from cveref where name='{bid}' and refsource='BID'"
	try:
		cur = conn.cursor()
		cur.execute(sql)
		result = cur.fetchone()
		cur.close()
		conn.commit()
	except:
		print(sql)

	if result == None:
		sql = f"insert into cveref(ref, name, refsource, publication, isExploit) \
			values('{url}', '{bid}', 'BID-ADD', '{date}', 1)"
		#print(sql)
	else:
		isExploit = result[1]
		sql = f"update cveref set publication='{date}', isExploit=1 where id={result[0]}"
		#print(sql)
	try:
		cur = conn.cursor()
		cur.execute(sql)
		cur.close()
		conn.commit()
	except:
		print(sql)
		conn.rollback()


def BidParser(bid):
	url = f'https://www.securityfocus.com/bid/{bid}/exploit'
	content = requests.get(url = url, headers = header).content.decode("iso-8859-1")
	#try:
	soup = BeautifulSoup(content, 'lxml')
	div = soup.find('div', attrs={'id':'vulnerability'})
	if 'vuldb@securityfocus.com' in div.text:
		return ''
	href = div.find_all('a')
	if len(href) < 1:
		return ''
	sql = f"select reporttime from securityfocus where bid = '{bid}'"
	try:
		cur = conn.cursor()
		cur.execute(sql)
		result = cur.fetchone()
		cur.close()
		conn.commit()
	except:
		print(sql)
	if result == None:
		print(f'securityfocus has not {bid}')
	else:
		date = result[0]
		updateBIDExploitTime(bid, date, url, div.text)
	#except:
		#print(url + ' can not access')
		#return ''
		
def getBidExploit():
	file = open('OpenBSDBIDList.txt', 'r')
	for line in file:
		bid = line.strip()
		BidParser(bid)

def getBugzillaOpentime(bugid):
	url = 'https://bugzilla.mozilla.org/show_bug.cgi?id=' + bugid
	content = requests.get(url = url, headers = headers).content.decode('utf-8')
	bs = BeautifulSoup(content, 'lxml')
	spans = bs.find_all('span', attrs={'class':'bug-time-label'})

	for span in spans:
		if 'Opened' in span.text:
			real_time = span.span.get('title')[:10]
			return real_time
	print(f'{bugid} can not get opentime')
	return ''

def updateBugzillaTime():
	sql = "select id, ref, publication from cveref where isExploit=1"
	try:
		cur = conn.cursor()
		cur.execute(sql)
		result = cur.fetchall()
		cur.close()
		conn.commit()
	except:
		print(sql)

	for r in result:
		if r[2] != None:
			continue
		myid = r[0]
		if r[1] == '' or 'https://bugzilla.mozilla.org' not in r[1]:
			continue
		publication = ''
		if 'https://bugzilla.mozilla.org/show_bug.cgi' in r[1]:
			bugid = r[1].split('=')[1]
			publication = getBugzillaOpentime(bugid)

		if 'https://bugzilla.mozilla.org/buglist.cgi' in r[1]:
			bugList = r[1].split('=')[1].split('%2C')
			publication = '2020-12-31'
			for bugid in bugList:
				opentime = getBugzillaOpentime(bugid)
				if opentime == '':
					continue
				if opentime < publication:
					publication = opentime
		if publication == '' or publication == '2020-12-31':
			print(f'{myid} {r[0]} no publication')
			continue

		sql = f"update cveref set publication = '{publication}' where id = {myid}"
		try:
			cur = conn.cursor()
			cur.execute(sql)
			cur.close()
			conn.commit()
		except:
			print(sql)
			conn.rollback()



if __name__ == '__main__':
	updateBugzillaTime()
	#main()
	#mostSites()
	#getExploitPattern()
	#getExploitFromEDB()
	#getBidExploit()